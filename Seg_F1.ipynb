{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seg_F1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQRCdKp8mE8e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "from scipy import io\n",
        "from torchvision.transforms import transforms\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import transforms\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import copy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsVE0c4GmqNW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x-S6VGyl25a"
      },
      "source": [
        "class iouEval:\n",
        "\n",
        "    def __init__(self, nClasses, device, ignoreIndex=-1):\n",
        "        self.nClasses = nClasses\n",
        "        self.ignoreIndex = ignoreIndex if nClasses>ignoreIndex else -1 #if ignoreIndex is larger than nClasses, consider no ignoreIndex\n",
        "        self.reset()\n",
        "        self.device = device\n",
        "\n",
        "    def reset (self):\n",
        "        classes = self.nClasses if self.ignoreIndex==-1 else self.nClasses-1\n",
        "        self.tp = torch.zeros(classes).double()\n",
        "        self.fp = torch.zeros(classes).double()\n",
        "        self.fn = torch.zeros(classes).double()        \n",
        "\n",
        "    def addBatch(self, x, y):   #x=preds, y=targets\n",
        "        #sizes should be \"batch_size x nClasses x H x W\"\n",
        "        \n",
        "        #print (\"X is cuda: \", x.is_cuda)\n",
        "        #print (\"Y is cuda: \", y.is_cuda)\n",
        "\n",
        "        if (x.is_cuda or y.is_cuda):\n",
        "            x = x.to(self.device)\n",
        "            y = y.to(self.device)\n",
        "\n",
        "        #if size is \"batch_size x 1 x H x W\" scatter to onehot\n",
        "        if (x.size(1) == 1):\n",
        "            x_onehot = torch.zeros(x.size(0), self.nClasses, x.size(2), x.size(3))  \n",
        "            if x.is_cuda:\n",
        "                x_onehot = x_onehot.to(self.device)\n",
        "            x_onehot.scatter_(1, x, 1).float()\n",
        "        else:\n",
        "            x_onehot = x.float()\n",
        "\n",
        "        if (y.size(1) == 1):\n",
        "            y_onehot = torch.zeros(y.size(0), self.nClasses, y.size(2), y.size(3))\n",
        "            if y.is_cuda:\n",
        "                y_onehot = y_onehot.to(self.device)\n",
        "            y_onehot.scatter_(1, y, 1).float()\n",
        "        else:\n",
        "            y_onehot = y.float()\n",
        "\n",
        "        if (self.ignoreIndex != -1): \n",
        "            ignores = y_onehot[:,self.ignoreIndex].unsqueeze(1)\n",
        "            x_onehot = x_onehot[:, :self.ignoreIndex]\n",
        "            y_onehot = y_onehot[:, :self.ignoreIndex]\n",
        "        else:\n",
        "            ignores=0\n",
        "\n",
        "\n",
        "        tpmult = x_onehot * y_onehot    #times prediction and gt coincide is 1\n",
        "        tp = torch.sum(torch.sum(torch.sum(tpmult, dim=0, keepdim=True), dim=2, keepdim=True), dim=3, keepdim=True).squeeze()\n",
        "        fpmult = x_onehot * (1-y_onehot-ignores) #times prediction says its that class and gt says its not (subtracting cases when its ignore label!)\n",
        "        fp = torch.sum(torch.sum(torch.sum(fpmult, dim=0, keepdim=True), dim=2, keepdim=True), dim=3, keepdim=True).squeeze()\n",
        "        fnmult = (1-x_onehot) * (y_onehot) #times prediction says its not that class and gt says it is\n",
        "        fn = torch.sum(torch.sum(torch.sum(fnmult, dim=0, keepdim=True), dim=2, keepdim=True), dim=3, keepdim=True).squeeze() \n",
        "\n",
        "        self.tp += tp.double().cpu()\n",
        "        self.fp += fp.double().cpu()\n",
        "        self.fn += fn.double().cpu()\n",
        "\n",
        "    def getIoU(self):\n",
        "        num = self.tp\n",
        "        den = self.tp + self.fp + self.fn + 1e-15\n",
        "        iou = num / den\n",
        "        return torch.mean(iou), iou     #returns \"iou mean\", \"iou per class\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su_KNzOwn_oN"
      },
      "source": [
        "def convrelu(in_channels, out_channels, kernel, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self,NUM_CLASSES, p = 0.35):\n",
        "        super(Net,self).__init__()\n",
        "\n",
        "        self.base_model = models.resnet34(pretrained=True)\n",
        "        self.base_layers = list(self.base_model.children())\n",
        "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
        "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
        "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
        "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
        "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
        "        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
        "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
        "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
        "\n",
        "        self.upsample4 = nn.ConvTranspose2d(256,256,3,2,1,1)\n",
        "        self.upsample3 = nn.ConvTranspose2d(128,128,3,2,1,1)\n",
        "        self.upsample2 = nn.ConvTranspose2d(64,64,3,2,1,1)\n",
        "        self.upsample1 = nn.ConvTranspose2d(64,64,3,2,1,1)\n",
        "        self.upsample0 = nn.ConvTranspose2d(32,32,3,2,1,1)\n",
        "        \n",
        "        self.conv_up4 = convrelu(512 , 256 , 3 , 1)\n",
        "        self.conv_up3 = convrelu(256 , 128, 3, 1)\n",
        "        self.conv_up2 = convrelu(128, 64, 3, 1)\n",
        "        self.conv_up1 = convrelu(64 , 64, 3, 1)\n",
        "        self.conv_up0 = convrelu(64, 32, 3, 1)\n",
        "\n",
        "        self.conv_original_size0 = convrelu(3, 32, 3, 1)\n",
        "        self.conv_original_size1 = convrelu(32, 32, 3, 1)\n",
        "        self.conv_original_size2 = convrelu(32, 16, 3, 1)\n",
        "\n",
        "        self.conv_last = nn.Conv2d(16, NUM_CLASSES, 1)\n",
        "        self.dropout = nn.Dropout(p) \n",
        "\n",
        "    def forward(self, input):\n",
        "        x_original = self.conv_original_size0(input)\n",
        "        x_original = self.conv_original_size1(x_original)\n",
        "        #print(x_original.shape)\n",
        "        layer0 = self.layer0(input) \n",
        "        #print(layer0.shape)\n",
        "        layer1 = self.layer1(layer0) #dropout can be added here inside\n",
        "        \n",
        "        layer2 = self.layer2(layer1) #dropout can be added here inside\n",
        "        \n",
        "        layer3 = self.layer3(layer2) #dropout can be added here inside\n",
        "          \n",
        "        layer4 = self.layer4(layer3) #dropout can be added here inside\n",
        "        \n",
        "        layer4 = self.dropout(self.layer4_1x1(layer4)) \n",
        "        \n",
        "        layer4 = self.conv_up4(layer4) #256\n",
        "        \n",
        "        x = self.upsample4(layer4) #256\n",
        "        layer3 = self.layer3_1x1(layer3) # 256\n",
        "        #print('first concat:',x.shape,layer3.shape)\n",
        "        x = x + layer3 #torch.cat([x, layer3], dim=1) #256\n",
        "        \n",
        "        #print(x.shape)\n",
        "        x = self.conv_up3(x) # 128\n",
        "        #print(x.shape)\n",
        "        x = self.upsample3(x) # 128\n",
        "        layer2 = self.layer2_1x1(layer2) #128\n",
        "        #print('second concat', x.shape,layer2.shape)\n",
        "        x = x + layer2#torch.cat([x, layer2], dim=1) # 128\n",
        "        x = self.conv_up2(x) #64\n",
        "\n",
        "        x = self.upsample2(x) #64\n",
        "        layer1 = self.layer1_1x1(layer1) #64\n",
        "\n",
        "        x = x + layer1 #torch.cat([x, layer1], dim=1)\n",
        "        x = self.conv_up1(x) #64\n",
        "\n",
        "        x = self.upsample1(x) #64\n",
        "        layer0 = self.layer0_1x1(layer0) #64\n",
        "\n",
        "        x =  x + layer0 #torch.cat([x, layer0], dim=1)\n",
        "        x = self.conv_up0(x) #32\n",
        "\n",
        "        x = self.upsample0(x) #32\n",
        "\n",
        "        x = x + x_original#torch.cat([x, x_original], dim=1) #32\n",
        "        x = self.conv_original_size2(x) #16\n",
        "\n",
        "        out = self.conv_last(x) #6\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gNVNY9noALc"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "NUM_CLASSES = 14\n",
        "OPT_LEARNING_RATE_INIT \t= 1e-3\n",
        "\n",
        "OPT_BETAS \t\t= (0.9, 0.999)\n",
        "OPT_EPS_LOW \t\t= 1e-08\n",
        "OPT_WEIGHT_DECAY \t= 1e-4\n",
        "\n",
        "image_path = '/content/drive/MyDrive/F1_datasets/13Labels/SUNRGBD-train_images' \n",
        "label_path = '/content/drive/MyDrive/F1_datasets/13Labels/train13labels'\n",
        "savedir = '/content/drive/MyDrive/F1_datasets/13Labels'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n8F_7croRam"
      },
      "source": [
        "image_list = os.listdir(image_path)\n",
        "image_list.sort()\n",
        "\n",
        "label_list = os.listdir(label_path)\n",
        "label_list.sort()\n",
        "\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "# class_weights = torch.tensor()\n",
        "ARGS_NUM_EPOCHS = 50\n",
        "tran_batch_size = val_batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FSkyPOboUKv"
      },
      "source": [
        "Data = MyDataset(mean,std,image_path,label_path,label_list,image_list)\n",
        "train_set, val_set = torch.utils.data.random_split(Data, [len(image_list) - 500, 500])\n",
        "train_loader = DataLoader(train_set, batch_size=tran_batch_size,shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_set, batch_size=val_batch_size,shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcfIUTHioWuF"
      },
      "source": [
        "class CrossEntropyLoss2d(torch.nn.Module):\n",
        "\tdef __init__(self, weight=None):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.loss = torch.nn.NLLLoss(weight=weight)\n",
        "\n",
        "\tdef forward(self, outputs, targets,mask=None):\n",
        "\t\treturn self.loss(torch.nn.functional.log_softmax(outputs, dim=1),targets)\n",
        "\n",
        "# weight = class_weights.cuda()\n",
        "# criterion = CrossEntropyLoss2d(weight=weight)\n",
        "criterion = CrossEntropyLoss2d()\n",
        "iou_best = 0\n",
        "model = Net(NUM_CLASSES,0.2).to(device)\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "  model.parameters(),\n",
        "  OPT_LEARNING_RATE_INIT,\n",
        "  OPT_BETAS,\n",
        "  eps = OPT_EPS_LOW,\n",
        "  weight_decay = OPT_WEIGHT_DECAY \n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1JnJ2vkod2s"
      },
      "source": [
        "best_iou = 0\n",
        "\n",
        "for epoch in range(ARGS_NUM_EPOCHS+1):\n",
        "  print(\"\\n ---------------- Epoch #\", epoch, \"------------------\\n\")\n",
        "  epoch_loss = []\n",
        "  iters = 0\n",
        "  model.train()\n",
        "  iouEvalTrain = iouEval(NUM_CLASSES,device)\n",
        "  \n",
        "  for step, (image,label) in enumerate(train_loader):\n",
        "\n",
        "    iters += 1\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    output = model(image)\n",
        "\n",
        "    iouEvalTrain.addBatch(\n",
        "      output.max(1)[1].unsqueeze(1).data,\n",
        "      label.long().data\n",
        "    )\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(output,label[:,0].long())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss.append(loss.item())\n",
        "    \n",
        "  \n",
        "  avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
        "  iouTrain, iou_classes = iouEvalTrain.getIoU()\n",
        "\n",
        "  print('[TRAINING] [Average loss]:{loss} [avg_iou]:{iou} [bg]:{bg} [roads]:{roads} [buildings]:{buildings} [vegetation]:{vegetation}'.format(\n",
        "        loss = avg_loss,\n",
        "        iou =  iouTrain))\n",
        "\n",
        "  epoch_test_loss = []\n",
        "  model.eval()\n",
        "  iouEvalTest = iouEval(NUM_CLASSES,device)\n",
        "  \n",
        "  for step, (image,label) in enumerate(test_loader):\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    output = model(image)\n",
        "\n",
        "    iouEvalTest.addBatch(\n",
        "      output.max(1)[1].unsqueeze(1).data,\n",
        "      label.long().data\n",
        "    )\n",
        "\n",
        "    loss = criterion(output,label[:,0].long())\n",
        "    epoch_test_loss.append(loss.item())\n",
        "    \n",
        "  \n",
        "  avg_loss = sum(epoch_test_loss) / len(epoch_test_loss)\n",
        "  iouTest, iou_classes = iouEvalTest.getIoU()\n",
        "\n",
        "  \n",
        "\n",
        "  print('[VALIDATION] [avg_val_loss]:{loss} [avg_iou]:{iou} [bg]:{bg} [roads]:{roads} [buildings]:{buildings} [vegetation]:{vegetation}'.format(\n",
        "        loss = avg_loss,\n",
        "        iou =  iouTest,\n",
        "        bg = iou_classes[0]))\n",
        "  \n",
        "  if(iouTest > iou_best):\n",
        "      iou_best = iouTest\n",
        "      torch.save(model.state_dict(), savedir + '/model_best.pth')\n",
        "      print('[SAVED] Best Model epoch:', epoch ,savedir +'/model_best.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}